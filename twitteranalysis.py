# -*- coding: utf-8 -*-
"""TwitterAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w9O39HpZ-FbzLhGv3y101Zw6Xtrm-BGo
"""

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder
import re
import nltk
from nltk import word_tokenize

# Load datasets
train = pd.read_csv("twitter_training.csv", header=None)
val = pd.read_csv("twitter_validation.csv", header=None)

# Data preprocessing
train.columns = ['id', 'information', 'type', 'text']
val.columns = ['id', 'information', 'type', 'text']

train["lower"] = train['text'].str.lower().apply(lambda x: re.sub('[^A-Za-z0-9 ]+', ' ', str(x)))
val["lower"] = val['text'].str.lower().apply(lambda x: re.sub('[^A-Za-z0-9 ]+', ' ', str(x)))

nltk.download('stopwords')

# Bag of Words transformation
bow_counts = CountVectorizer(
    tokenizer=word_tokenize,
    stop_words=nltk.corpus.stopwords.words('english'),
    ngram_range=(1, 1)
)

nltk.download('punkt')

# Train-Test splitting
reviews_train, reviews_test = train_test_split(train, test_size=0.2, random_state=0)

X_train_bow = bow_counts.fit_transform(reviews_train.lower)
X_test_bow = bow_counts.transform(reviews_test.lower)
X_val_bow = bow_counts.transform(val.lower)

y_train_bow = reviews_train['type']
y_test_bow = reviews_test['type']
y_val_bow = val['type']

# Logistic Regression model
model1 = LogisticRegression(C=1, solver="liblinear", max_iter=200)
model1.fit(X_train_bow, y_train_bow)

# Evaluate on test dataset
test_pred = model1.predict(X_test_bow)
print("Logistic Regression Accuracy on Test Data:", accuracy_score(y_test_bow, test_pred) * 100)

# Evaluate on validation dataset
val_pred = model1.predict(X_val_bow)
print("Logistic Regression Accuracy on Validation Data:", accuracy_score(y_val_bow, val_pred) * 100)

# XGBoost model
le = LabelEncoder()
y_train_bow_num = le.fit_transform(y_train_bow)
y_test_bow_num = le.transform(y_test_bow)
y_val_bow_num = le.transform(y_val_bow)

XGB = XGBClassifier(objective="multi:softmax", n_estimators=1000, colsample_bytree=0.6, subsample=0.6)
XGB.fit(X_train_bow, y_train_bow_num)

# Evaluate on test dataset
test_pred_xgb = XGB.predict(X_test_bow)
print("XGBoost Accuracy on Test Data:", accuracy_score(y_test_bow_num, test_pred_xgb) * 100)

# Evaluate on validation dataset
val_pred_xgb = XGB.predict(X_val_bow)
print("XGBoost Accuracy on Validation Data:", accuracy_score(y_val_bow_num, val_pred_xgb) * 100)

# Load the dataset
dataset_path = "twitter_training.csv"
df = pd.read_csv(dataset_path, header=None)

# Display the first few rows of the DataFrame to inspect its structure
print("First few rows of the DataFrame:")
print(df.head())

# Analyze the structure of the DataFrame to determine the appropriate column names
num_columns = len(df.columns)
print("\nNumber of columns in the DataFrame:", num_columns)

# If necessary, adjust the column names accordingly
expected_column_names = ['ID', 'Information', 'Sentiment', 'Text']
if num_columns == 4:
    df.columns = expected_column_names
    print("\nColumn names adjusted successfully.")
else:
    print("\nError: The DataFrame does not have the expected number of columns.")

# Select a random line
random_line = df.sample(n=1)

# Output the selected line
print("\nRandom line from the dataset:")
print(random_line)

# Analyze the selected line
print("\nAnalysis:")
print("- ID:", random_line['ID'].values[0])
print("- Information/Brand:", random_line['Information'].values[0])
print("- Sentiment:", random_line['Sentiment'].values[0])
print("- Text:", random_line['Text'].values[0])

# Additional analysis of the text
print("\nAnalysis of the text:")
text = random_line['Text'].values[0]
if "kill" in text.lower():
    print("- The text contains a mention of 'kill', suggesting a potentially negative sentiment.")
else:
    print("- No indication of negative sentiment based on the text.")